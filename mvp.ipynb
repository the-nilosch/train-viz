{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cba566ae0eb7252",
   "metadata": {},
   "source": [
    "# Visualizing Embedding Evolution During Training\n",
    "\n",
    "In this notebook, we train an MLP on MNIST and visualize how hidden representations (embeddings) evolve over training using t-SNE. This gives insight into how class structure emerges in the latent space over time."
   ]
  },
  {
   "cell_type": "code",
   "id": "39efc2648a62550",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "668a40f6b2187af1",
   "metadata": {},
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#train_subset, _ = torch.utils.data.random_split(train_data, [10000, len(train_data)-10000])\n",
    "#train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# First, get all test labels\n",
    "test_targets = test_data.targets.numpy()\n",
    "\n",
    "# Define how many samples per class\n",
    "samples_per_class = 200\n",
    "num_classes = 10\n",
    "\n",
    "# Collect indices (balanced subset)\n",
    "selected_indices = []\n",
    "for class_id in range(num_classes):\n",
    "    class_indices = np.where(test_targets == class_id)[0]\n",
    "    chosen = np.random.choice(class_indices, size=samples_per_class, replace=False)\n",
    "    selected_indices.extend(chosen)\n",
    "\n",
    "# Create a test subset DataLoader (shuffling not needed)\n",
    "test_subset = Subset(test_data, selected_indices)\n",
    "test_subset_loader = DataLoader(test_subset, batch_size=128, shuffle=False)"
   ],
   "id": "9282c10b4543a664",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(test_subset))"
   ],
   "id": "521c8237be323e86",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8de7fdb488369387",
   "metadata": {},
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=28*28, hidden_dim=128, num_classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, return_embedding=False):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        h = F.relu(self.fc1(x))\n",
    "        out = self.fc2(h)\n",
    "        if return_embedding:\n",
    "            return out, h\n",
    "        return out\n",
    "\n",
    "model = MLP().to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "acbd135b4291354a",
   "metadata": {},
   "source": [
    "# Training parameters\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Metrics\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# Embeddings\n",
    "# train_embeddings_all = []\n",
    "# test_embeddings_all = []\n",
    "# train_labels_all = []\n",
    "# test_labels_all = []\n",
    "test_subset_embeddings = []\n",
    "test_subset_labels = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # === Train phase ===\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    epoch_train_embeddings = []\n",
    "    epoch_train_labels = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, embedding = model(data, return_embedding=True)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics\n",
    "        epoch_train_loss += loss.item()\n",
    "        _, preds = torch.max(output, dim=1)\n",
    "        correct_train += (preds == target).sum().item()\n",
    "        total_train += target.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = []\n",
    "            batch_labels = []\n",
    "\n",
    "            for data_sub, target_sub in test_subset_loader:\n",
    "                data_sub, target_sub = data_sub.to(device), target_sub.to(device)\n",
    "                _, emb = model(data_sub, return_embedding=True)\n",
    "                batch_embeddings.append(emb.cpu().numpy())\n",
    "                batch_labels.append(target_sub.cpu().numpy())\n",
    "\n",
    "            test_subset_embeddings.append(np.concatenate(batch_embeddings, axis=0))\n",
    "            test_subset_labels.append(np.concatenate(batch_labels, axis=0))\n",
    "\n",
    "        # Store embeddings\n",
    "        #epoch_train_embeddings.append(embedding.cpu().detach().numpy())\n",
    "        #epoch_train_labels.append(target.cpu().numpy())\n",
    "\n",
    "    train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_acc = correct_train / total_train\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    #train_embeddings_all.append(np.concatenate(epoch_train_embeddings, axis=0))\n",
    "    #train_labels_all.append(np.concatenate(epoch_train_labels, axis=0))\n",
    "\n",
    "    # === Eval phase ===\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    epoch_val_embeddings = []\n",
    "    epoch_val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, _ = model(data, return_embedding=True)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            epoch_val_loss += loss.item()\n",
    "            _, preds = torch.max(output, dim=1)\n",
    "            correct_val += (preds == target).sum().item()\n",
    "            total_val += target.size(0)\n",
    "\n",
    "            #epoch_val_embeddings.append(embedding.cpu().numpy())\n",
    "            #epoch_val_labels.append(target.cpu().numpy())\n",
    "\n",
    "    val_loss = epoch_val_loss / len(test_loader)\n",
    "    val_acc = correct_val / total_val\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    #test_embeddings_all.append(np.concatenate(epoch_val_embeddings, axis=0))\n",
    "    #test_labels_all.append(np.concatenate(epoch_val_labels, axis=0))\n",
    "\n",
    "    # === Print summary ===\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"| Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} \"\n",
    "          f\"| Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Epoch [50/50] | Train Loss: 0.0562, Acc: 0.9851 | Val Loss: 0.0848, Acc: 0.9739\n",
    "# Epoch [10/10] | Train Loss: 0.0370, Acc: 0.9894 | Val Loss: 0.0796, Acc: 0.9764"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plotting Training and Validation Loss\n",
    "plt.plot(range(epochs), train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "a95ef0daa6736e34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# tSNE Computation",
   "id": "d42d38317566660f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Labels should be the same everywhere\n",
    "print(labels[0])\n",
    "print(labels[1])"
   ],
   "id": "a1efef63394bcc79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "embeddings[0]",
   "id": "82ca31f5daab731e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Final epoch's data\n",
    "final_embeddings = embeddings[-1]\n",
    "final_labels = labels[-1]\n",
    "\n",
    "# Convert to NumPy arrays (if not already)\n",
    "final_embeddings = np.array(final_embeddings)\n",
    "final_labels = np.array(final_labels)\n",
    "\n",
    "# How many samples per class\n",
    "samples_per_class = 200\n",
    "num_classes = 10\n",
    "\n",
    "# Collect indices\n",
    "selected_indices = []\n",
    "for class_id in range(num_classes):\n",
    "    class_indices = np.where(final_labels == class_id)[0]\n",
    "    chosen = np.random.choice(class_indices, size=samples_per_class, replace=False)\n",
    "    selected_indices.extend(chosen)\n",
    "\n",
    "# Subsample embeddings and labels\n",
    "sampled_embeddings = final_embeddings[selected_indices]\n",
    "sampled_labels = final_labels[selected_indices]"
   ],
   "id": "28e2a6e16262d119",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Optional: Refresh tSNE\n",
    "epoch = 10\n",
    "\n",
    "# Final epoch's data\n",
    "final_embeddings = embeddings[epoch]\n",
    "final_labels = labels[epoch]\n",
    "\n",
    "# Subsample embeddings and labels\n",
    "sampled_embeddings = final_embeddings[selected_indices]\n",
    "sampled_labels = final_labels[selected_indices]"
   ],
   "id": "8baca24607ab1137",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(sampled_embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=sampled_labels, cmap='tab10', alpha=0.8)\n",
    "plt.title('t-SNE of Final Epoch Embeddings (Balanced Sample)')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.colorbar(label='Digit Label')\n",
    "plt.show()"
   ],
   "id": "87ac8540dd59a47e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Animation",
   "id": "ba593260b907ad0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# === Compute t-SNE per epoch using selected_indices ===\n",
    "tsne_results = []\n",
    "\n",
    "# Epoch 0: PCA init\n",
    "tsne = TSNE(n_components=2, init='pca', random_state=42)\n",
    "result = tsne.fit_transform(embeddings[0][selected_indices])\n",
    "tsne_results.append(result)\n",
    "\n",
    "# Epochs 1+: use previous output for init\n",
    "for epoch in range(1, len(embeddings)):\n",
    "    tsne = TSNE(n_components=2, init=tsne_results[-1], random_state=42)\n",
    "    result = tsne.fit_transform(embeddings[epoch][selected_indices])\n",
    "    tsne_results.append(result)\n",
    "\n",
    "# === Animation Setup ===\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "scatter = ax.scatter([], [], c=[], cmap='tab10', alpha=0.7)\n",
    "ax.set_xlim(-100, 100)\n",
    "ax.set_ylim(-100, 100)\n",
    "ax.set_xlabel('t-SNE Dimension 1')\n",
    "ax.set_ylabel('t-SNE Dimension 2')\n",
    "ax.set_title('t-SNE Embedding Evolution')\n",
    "\n",
    "# Use sampled_labels once — they're fixed\n",
    "def update(frame):\n",
    "    scatter.set_offsets(tsne_results[frame])\n",
    "    scatter.set_array(sampled_labels)\n",
    "    ax.set_title(f't-SNE Embedding – Epoch {frame + 1}')\n",
    "    return scatter,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(tsne_results), interval=1000, blit=True)\n",
    "#plt.show()"
   ],
   "id": "c72b5be0ea52bed9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Static figure (inline mode is fine)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot the initial frame (epoch 0)\n",
    "sc = ax.scatter(\n",
    "    tsne_results[0][:, 0], tsne_results[0][:, 1],\n",
    "    c=sampled_labels, cmap='tab10', alpha=0.7\n",
    ")\n",
    "ax.set_xlim(-100, 100)\n",
    "ax.set_ylim(-100, 100)\n",
    "ax.set_xlabel('t-SNE Dimension 1')\n",
    "ax.set_ylabel('t-SNE Dimension 2')\n",
    "title = ax.set_title(\"t-SNE Embedding – Epoch 1\")\n",
    "\n",
    "# Update function for slider\n",
    "def update_epoch(epoch):\n",
    "    print(epoch)\n",
    "    sc.set_offsets(tsne_results[epoch])\n",
    "    title.set_text(f't-SNE Embedding – Epoch {epoch + 1}')\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# IntSlider widget\n",
    "epoch_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(tsne_results) - 1,\n",
    "    step=1,\n",
    "    description='Epoch:',\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "# Connect slider to update function\n",
    "widgets.interact(update_epoch, epoch=epoch_slider)"
   ],
   "id": "eb7c38df273e3130",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# === Define experiment info ===\n",
    "model_name = model._get_name()\n",
    "# Build a base name with settings\n",
    "base_name = f\"tsne_{model_name}_e{epochs}_lr{learning_rate:.0e}\"  # e.g., tsne_MLP_e10_lr1e-03\n",
    "\n",
    "# Auto-increment file index\n",
    "i = 1\n",
    "while os.path.exists(f\"{base_name}_{i:03}.gif\"):\n",
    "    i += 1\n",
    "filename = f\"{base_name}_{i:03}.gif\"\n",
    "\n",
    "# Save the animation\n",
    "ani.save(filename, writer='pillow')\n",
    "print(f\"Saved animation as {filename}\")"
   ],
   "id": "5d91cfe35e646f63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "96c02c8df66f4e24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Video Animation",
   "id": "ec1b2a3e2c08b143"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "\n",
    "# === Interpolation between t-SNE results ===\n",
    "def interpolate_tsne(embeddings_list, steps=10):\n",
    "    interpolated = []\n",
    "    for a, b in zip(embeddings_list[:-1], embeddings_list[1:]):\n",
    "        for alpha in np.linspace(0, 1, steps, endpoint=False):\n",
    "            interp = (1 - alpha) * a + alpha * b\n",
    "            interpolated.append(interp)\n",
    "    interpolated.append(embeddings_list[-1])  # include final frame\n",
    "    return interpolated\n",
    "\n",
    "# === Compute t-SNE per epoch using selected_indices ===\n",
    "tsne_results = []\n",
    "\n",
    "# Epoch 0\n",
    "tsne = TSNE(n_components=2, init='pca', random_state=42)\n",
    "result = tsne.fit_transform(embeddings[0][selected_indices])\n",
    "tsne_results.append(result)\n",
    "\n",
    "# Subsequent epochs\n",
    "for epoch in range(1, len(embeddings)):\n",
    "    tsne = TSNE(n_components=2, init=tsne_results[-1], random_state=42)\n",
    "    result = tsne.fit_transform(embeddings[epoch][selected_indices])\n",
    "    tsne_results.append(result)\n",
    "\n",
    "# === Interpolate between epochs ===\n",
    "tsne_results_interp = interpolate_tsne(tsne_results, steps=5)\n",
    "\n",
    "# === Animation setup ===\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "scatter = ax.scatter([], [], cmap='tab10', alpha=0.7)\n",
    "ax.set_xlim(-100, 100)\n",
    "ax.set_ylim(-100, 100)\n",
    "ax.set_xlabel('t-SNE Dimension 1')\n",
    "ax.set_ylabel('t-SNE Dimension 2')\n",
    "title = ax.set_title('t-SNE Embedding Evolution')\n",
    "\n",
    "def update(frame):\n",
    "    scatter.set_offsets(tsne_results_interp[frame])\n",
    "    scatter.set_array(sampled_labels)\n",
    "    title.set_text(f't-SNE Embedding Evolution – Frame {frame + 1}')\n",
    "    return scatter,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(tsne_results_interp), interval=100, blit=True)"
   ],
   "id": "74b54248103e3706",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import HTML\n",
    "HTML(ani.to_jshtml())"
   ],
   "id": "a8c1511fca0efa43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Save as MP4 (with ffmpeg) ===\n",
    "model_name = model._get_name()\n",
    "lr = learning_rate\n",
    "base_name = f\"tsne_{model_name}_e{epochs}_lr{lr:.0e}\"\n",
    "i = 1\n",
    "while os.path.exists(f\"{base_name}_{i:03}.mp4\"):\n",
    "    i += 1\n",
    "filename = f\"{base_name}_{i:03}.mp4\"\n",
    "\n",
    "ani.save(filename, writer='ffmpeg', dpi=150)\n",
    "print(f\"Saved animation as {filename}\")"
   ],
   "id": "4acbea804df37a58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8e0595b9406907d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3dca10d6150d90b2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
