{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5326ecff0764644",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Neuro-Visualizer\n",
    "(Run beginning always)"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:39:06.565672Z",
     "start_time": "2025-07-15T09:39:04.352028Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from NeuroVisualizer.neuro_aux.AEmodel import UniformAutoencoder\n",
    "from NeuroVisualizer.neuro_aux.utils import get_files\n",
    "\n",
    "from helper.neuro_viz import get_dataloader_flat"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "fcbb44e41502b669",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T09:39:07.497289Z",
     "start_time": "2025-07-15T09:39:07.378107Z"
    }
   },
   "source": [
    "run = \"cifar10_CNN_128_0.8699\"\n",
    "dataset_name = 'cifar10'\n",
    "model_name = 'CNN'\n",
    "\n",
    "from helper.data_manager import load_training_data\n",
    "\n",
    "results = load_training_data(run)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No file found at trainings/cifar10_CNN_128_0.8699.h5",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCNN\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mhelper\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_manager\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_training_data\n\u001B[0;32m----> 7\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mload_training_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/train-viz/helper/data_manager.py:82\u001B[0m, in \u001B[0;36mload_training_data\u001B[0;34m(run_id)\u001B[0m\n\u001B[1;32m     80\u001B[0m file_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrainings\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(file_path):\n\u001B[0;32m---> 82\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo file found at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     84\u001B[0m data \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m h5py\u001B[38;5;241m.\u001B[39mFile(file_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: No file found at trainings/cifar10_CNN_128_0.8699.h5"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035cac7-16bf-49e4-911d-58b68b9738e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"ll_flattened_weights_dir\"] = 'run-0001'\n",
    "\n",
    "run_id = results[\"ll_flattened_weights_dir\"]\n",
    "print(run_id)\n",
    "\n",
    "model_file = f'ae_models/{run_id}.pt'\n",
    "model_folder = f\"trainings/{run_id}\"\n",
    "\n",
    "val_losses = results[\"val_losses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5627ff7e507e37",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adjust this path to your folder\n",
    "\n",
    "pt_files = get_files(model_folder, prefix=\"model-\")\n",
    "print(f\"Found {len(pt_files)} checkpoint files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb78a0bbfb31f46",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train AE Model\n",
    "Run this part to train an AE-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f3470dc9303199",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 4 #32\n",
    "\n",
    "pt_files_subset = pt_files[:]\n",
    "loader, normalizer = get_dataloader_flat(pt_files_subset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d44219a8c9983",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_dim = loader.dataset[0].shape[0]\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "\n",
    "latent_dim = 2\n",
    "num_layers = 3\n",
    "# Aggressive compression\n",
    "#h = [input_dim, 512, 128]  # Aggressive compression\n",
    "h = [input_dim, 64, 32]  # Aggressive compression\n",
    "#h = [input_dim, 256, 64]\n",
    "\n",
    "ae = UniformAutoencoder(input_dim, num_layers, latent_dim, h=h).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a34c750998a0b4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helper.neuro_viz import train_autoencoder\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "trained_model = train_autoencoder(\n",
    "    model=ae,\n",
    "    train_loader=loader,\n",
    "    device=device,\n",
    "    save_path=model_file,\n",
    "    num_epochs=100,\n",
    "    lr=1e-3,\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f91c87f59dfb3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Best models already saved\n",
    "# os.makedirs(\"ae_models\", exist_ok=True)\n",
    "# torch.save(ae.state_dict(), \"ae_models/ae_model_mlp_mnist.pt\")\n",
    "# print(\"AE saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f04cc2b2a5a865",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Visualize Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c59ac3e986644",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from NeuroVisualizer.neuro_aux.AEmodel import UniformAutoencoder\n",
    "from NeuroVisualizer.neuro_aux.utils import get_files, repopulate_model\n",
    "from NeuroVisualizer.neuro_aux.trajectories_data import get_trajectory_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9a413afb8e33d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "loss_name = 'test_loss'\n",
    "whichloss = 'mse' # this is CrossEntropyLoss\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20578face5ae73b",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get file list\n",
    "# pt_files = get_files(model_folder, prefix=\"model-\")\n",
    "\n",
    "# Load AE\n",
    "example_tensor = torch.load(pt_files[0])\n",
    "input_dim = example_tensor.shape[0]\n",
    "latent_dim = 2\n",
    "num_of_layers = 3\n",
    "h = [input_dim, 512, 128]\n",
    "\n",
    "best_model = UniformAutoencoder(input_dim, num_of_layers, latent_dim, h=h).to(device)\n",
    "best_model.load_state_dict(torch.load(model_file))\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aac66468474164",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---- Load data ----\n",
    "from neuro_viz_helper import get_dataloader_flat\n",
    "\n",
    "trajectory_loader, transform = get_dataloader_flat(pt_files, batch_size, shuffle=False) #[:5] for Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6846d7b6fe6c96a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vision_classification import init_mlp_for_dataset\n",
    "from neuro_viz_helper import Loss\n",
    "\n",
    "model = init_mlp_for_dataset(dataset_name, hidden_dims=[254, 64], dropout=0.1).to(device)\n",
    "loss_obj = Loss(dataset_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264ebc0a37b88af",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuro_viz_helper import compute_trajectory\n",
    "\n",
    "trajectory_coordinates, trajectory_models, trajectory_losses = compute_trajectory(\n",
    "    trajectory_loader,\n",
    "    best_model,\n",
    "    transform,\n",
    "    loss_obj,\n",
    "    model,\n",
    "    loss_name,\n",
    "    whichloss,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a432896303748a7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.plot(results[\"val_losses\"], label='Logged Validation Loss', marker='o')\n",
    "plt.plot(trajectory_losses.cpu().numpy(), label='AE-Projected Validation Loss', marker='x')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Validation Loss: Training Log vs. AE-Projected Trajectory')\n",
    "plt.xlabel('Checkpoint Index')\n",
    "plt.ylabel('Loss (e.g. NLL)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e322ad33c28b9b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1️⃣ Generate grid in latent space\n",
    "from neuro_viz_helper import generate_latent_grid, compute_grid_losses\n",
    "xx, yy, grid_coords = generate_latent_grid(\n",
    "    min_map=-1, max_map=1, xnum=3, device=device\n",
    ")\n",
    "\n",
    "# 2️⃣ Decode grid and compute losses\n",
    "model = init_mlp_for_dataset(dataset_name, hidden_dims=[254, 64], dropout=0.1).to(device)\n",
    "\n",
    "grid_losses = compute_grid_losses(\n",
    "    grid_coords,\n",
    "    transform,\n",
    "    best_model,\n",
    "    model,\n",
    "    loss_obj,\n",
    "    loss_name,\n",
    "    whichloss,\n",
    "    device\n",
    ")\n",
    "\n",
    "# 3️⃣ Reshape to grid\n",
    "grid_losses = grid_losses.view(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ebf45f637a2183",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(grid_losses.min().item(), grid_losses.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47df1891d8bef28",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe82af7fb974760",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rec_grid_models = best_model.decoder(grid_coords)\n",
    "rec_grid_models = rec_grid_models*transform.std.to(device) + transform.mean.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41897ed199161985",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "# === PREPARE LOSSES (flip sign since NLL is negative) ===\n",
    "grid_losses_pos = -grid_losses.detach().cpu().numpy()\n",
    "traj_losses_pos = -trajectory_losses.detach().cpu().numpy()\n",
    "\n",
    "# Avoid zeros or negative values for LogNorm\n",
    "grid_losses_pos[grid_losses_pos <= 1e-3] = 1e-3\n",
    "traj_losses_pos[traj_losses_pos <= 1e-3] = 1e-3\n",
    "\n",
    "# === SHARED COLOR SCALE ===\n",
    "all_losses = np.concatenate([grid_losses_pos.flatten(), traj_losses_pos])\n",
    "vmin = np.clip(all_losses.min() / 1.2, 1e-3, None)\n",
    "vmax = all_losses.max() * 1.2\n",
    "\n",
    "if vmin >= vmax or np.isclose(vmin, vmax):\n",
    "    vmax = vmin * 10\n",
    "    print(f\"Adjusted nearly-constant losses: vmin={vmin}, vmax={vmax}\")\n",
    "\n",
    "levels = np.logspace(np.log10(vmin), np.log10(vmax), 30)\n",
    "shared_norm = LogNorm(vmin=vmin, vmax=vmax)\n",
    "shared_cmap = 'viridis' #hot\n",
    "\n",
    "# === BEGIN PLOTTING ===\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# -- 1️⃣ Loss Landscape Contour --\n",
    "contour = ax.contourf(\n",
    "    xx.cpu().numpy(),\n",
    "    yy.cpu().numpy(),\n",
    "    grid_losses_pos,\n",
    "    levels=levels,\n",
    "    norm=shared_norm,\n",
    "    cmap=shared_cmap\n",
    ")\n",
    "cbar = plt.colorbar(contour, ax=ax, shrink=0.8)\n",
    "cbar.ax.set_ylabel('-NLL Loss (Higher is Better)', fontsize=12)\n",
    "\n",
    "# -- 2️⃣ Trajectory Lines --\n",
    "z = trajectory_coordinates.cpu().numpy()\n",
    "for i in range(len(z) - 1):\n",
    "    ax.plot([z[i, 0], z[i + 1, 0]], [z[i, 1], z[i + 1, 1]], color='k', linewidth=1)\n",
    "\n",
    "# -- 3️⃣ Trajectory Points with SAME Color Mapping --\n",
    "sc = ax.scatter(\n",
    "    z[:, 0], z[:, 1],\n",
    "    c=traj_losses_pos,\n",
    "    cmap=shared_cmap,\n",
    "    norm=shared_norm,\n",
    "    s=40,\n",
    "    edgecolors='k',\n",
    "    #label='Trajectory Points'\n",
    ")\n",
    "\n",
    "# -- 4️⃣ OPTIONAL: Density Contours --\n",
    "try:\n",
    "    from NeuroVisualizer.neuro_aux.utils import get_density\n",
    "    density = get_density(rec_grid_models.detach().cpu().numpy(), type='inverse', p=2)\n",
    "    density = density.reshape(xx.shape)\n",
    "    density_levels = np.logspace(\n",
    "        np.log10(max(density.min(), 1e-3)),\n",
    "        np.log10(density.max()),\n",
    "        15\n",
    "    )\n",
    "    CS_density = ax.contour(\n",
    "        xx.cpu().numpy(), yy.cpu().numpy(), density,\n",
    "        levels=density_levels,\n",
    "        colors='white',\n",
    "        linewidths=0.8\n",
    "    )\n",
    "    ax.clabel(CS_density, fmt=ticker.FormatStrFormatter('%.1f'), fontsize=7)\n",
    "except Exception as e:\n",
    "    print(\"Density contour skipped:\", e)\n",
    "\n",
    "# -- 5️⃣ Labels, Grid, Style --\n",
    "ax.set_title('Loss Landscape with Training Trajectory', fontsize=14)\n",
    "ax.set_xlabel('Latent Dimension 1', fontsize=12)\n",
    "ax.set_ylabel('Latent Dimension 2', fontsize=12)\n",
    "#ax.legend(loc='best')\n",
    "ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# -- 6️⃣ Show or Save --\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9eb868b9361be4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ✅ Save to PDF\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "fig.savefig('plots/loss_landscape_with_trajectory.pdf', dpi=300, bbox_inches='tight', format='pdf')\n",
    "print(\"Saved PDF to plots/loss_landscape_with_trajectory.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (train-viz)",
   "language": "python",
   "name": "train-viz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
