{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77088f6553468de1",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Training TODOs\n",
    "- [x] MLP \n",
    "- [x] CIPHAR 10 / 100\n",
    "- [ ] ImageNet\n",
    "- [ ] NLP Models & Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba566ae0eb7252",
   "metadata": {},
   "source": [
    "**Environment:** Please use the standard (`train-viz`) environment here\n",
    "\n",
    "# Training\n",
    "### with Logging and Live-Visualization\n",
    "\n",
    "In this notebook, we train chosen Models with chosen Datasets.\n",
    "The training comprises many features:\n",
    "- **Setup & Reproducibility**: seeds for `torch`, `numpy`, `random`; deterministic CuDNN; auto–device (CPU/GPU).  \n",
    "- **Optimizer & SAM**: configures SGD/AdamW, weight-decay, optional Sharpness-Aware Minimizer (`use_sam`, `rho`).  \n",
    "- **Metrics Tracking**: epoch-wise train/val losses & accuracies; scheduler LR history.  \n",
    "- **Early Stopping**: halts after `patience` epochs without val-loss improvement.  \n",
    "- **Weight Snapshots**: save flattened weights each epoch (`save_model_weights_each_epoch`) for loss-landscape viz.  \n",
    "- **Embedding Snapshots**: capture embeddings from a fixed subset at configurable intervals (`embedding_records_per_epoch`).  \n",
    "- **Embedding Drift**: compute latent-space drift between successive snapshots.  \n",
    "- **Gradient Stats**: log gradient norms, max‐gradient, and grad/param ratios at batch intervals.  \n",
    "- **Live Plots**: dynamic subplots for loss/accuracy, gradients, LR schedule, drift, PCA, (cosine similarity placeholder).  \n",
    "- **Logging**: INFO-level history printed each epoch.  \n",
    "- **Return Payload**: dict with all histories, embeddings, drifts, gradient stats, LR schedule, weight-snapshot dir, model repr, and config.  \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "39efc2648a62550",
   "metadata": {},
   "source": [
    "%matplotlib widget\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # Bei Multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)  # Should print something like '11.8'\n",
    "print(\"Using device:\", device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5679c45d-ffb5-4417-8998-99255b7487ef",
   "metadata": {},
   "source": [
    "### Choose Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "668a40f6b2187af1",
   "metadata": {},
   "source": [
    "from helper.vision_classification import init_dataset\n",
    "\n",
    "#dataset = \"mnist\"\n",
    "dataset = \"cifar10\"\n",
    "#dataset = \"cifar100\"\n",
    "\n",
    "train_loader, test_loader, subset_loader = init_dataset(dataset, samples_per_class=100 if dataset != \"cifar100\" else 10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Choose model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "852eaa13c347375e"
  },
  {
   "cell_type": "code",
   "id": "d967979d-c634-4d89-a984-1f6dee7fccab",
   "metadata": {},
   "source": [
    "from helper.vision_classification import init_mlp_for_dataset, init_cnn_for_dataset, init_vit_for_dataset, init_resnet_for_dataset, init_densenet_for_dataset\n",
    "\n",
    "#model = init_mlp_for_dataset(dataset, hidden_dims=[512, 254, 128], dropout=0.1).to(device)\n",
    "#model = init_mlp_for_dataset(dataset, hidden_dims=[254, 64], dropout=0.1).to(device)\n",
    "\n",
    "model = init_cnn_for_dataset(dataset, conv_dims=[64, 128, 256], kernel_sizes=[5, 3, 3], hidden_dims=[256, 128], dropout=0.2, residual=True).to(device)\n",
    "#model = init_cnn_for_dataset(dataset, conv_dims=[64, 128, 256, 512], kernel_sizes=[5, 3, 3, 3], hidden_dims=[512, 256], dropout=0.2).to(device)\n",
    "#model = init_cnn_for_dataset(dataset, conv_dims=[128, 256, 512, 1024], kernel_sizes=[5, 3, 3, 3], hidden_dims=[1024, 256], dropout=0.2).to(device)\n",
    "\n",
    "#model = init_vit_for_dataset(dataset, emb_dim=32, depth=4, num_heads=4, mlp_dim=128, dropout=0.15, patch_size=4).to(device)\n",
    "#model = init_vit_for_dataset(dataset, emb_dim=64, depth=6, num_heads=8, mlp_dim=128, dropout=0.1, patch_size=7).to(device)\n",
    "\n",
    "# model = init_vit_for_dataset(dataset, emb_dim=192, depth=6, num_heads=6, mlp_dim=256, dropout=0.1, patch_size=4).to(device) #CIFAR100\n",
    "#model = init_vit_for_dataset(dataset, emb_dim=256, depth=12, num_heads=8, mlp_dim=512, dropout=0.15).to(device)\n",
    "\n",
    "#model = init_resnet_for_dataset(dataset, fc_hidden_dims=[128], dropout=0.2).to(device)\n",
    "\n",
    "#model = init_densenet_for_dataset(dataset, fc_hidden_dims=[128], dropout=0.2).to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "repr(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66ea2e83d076a518",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Choose Optimizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59a3b0d0bca1dcca"
  },
  {
   "cell_type": "code",
   "source": [
    "# Optional: Overwrites standard Optimizers\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.0005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.05,\n",
    "    nesterov=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ab7a794e482e0cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Sharpness-Aware Minimizer (Flag to choose SAMSGD)\n",
    "use_sam = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5b86ea48cda8a8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Loop"
   ],
   "metadata": {},
   "id": "38b750cb-c96d-4278-9aee-6e4e8f8d3f3d"
  },
  {
   "cell_type": "code",
   "id": "7a837fc86af75d6d",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from helper.train import train_model_with_embedding_tracking\n",
    "\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001) #0.001\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "results = train_model_with_embedding_tracking(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    subset_loader=subset_loader, #test_subset\n",
    "    num_classes=10 if \"cifar100\" != dataset else 100,\n",
    "    device=device,\n",
    "    epochs=50, #Max 50\n",
    "    learning_rate=0.001, # 0.0001\n",
    "    \n",
    "    save_model_weights_each_epoch=True, # For Loss Landscape (Neuro-Visualizer)\n",
    "    embedding_records_per_epoch=4,\n",
    "    track_embedding_drift=True,\n",
    "    track_scheduled_lr=True,\n",
    "    track_pca=False,\n",
    "    use_sam=use_sam,\n",
    "    patience=10\n",
    "    #optimizer=optimizer,\n",
    "    #scheduler=scheduler\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e3d2ff241035dd31",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "id": "86d51e40-2b40-444d-9709-358946c97454",
   "metadata": {},
   "source": [
    "from helper.data_manager import save_training_data\n",
    "\n",
    "run_folder = results[\"ll_flattened_weights_dir\"]\n",
    "run = f\"{run_folder}_{dataset}_{model.emb_dim}_{max(results['val_accuracies']):.4f}\"\n",
    "save_training_data(run, results)\n",
    "print(run)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b49920e6f763c2f9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (train-viz)",
   "language": "python",
   "name": "train-viz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
