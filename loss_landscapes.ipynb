{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# OLD\n",
    "See Neuro_visualizer Notebook"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbf62801832f7735"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from NeuroVisualizer.neuro_aux.AEmodel import UniformAutoencoder\n",
    "from NeuroVisualizer.neuro_aux.utils import get_files\n",
    "from NeuroVisualizer.neuro_aux.trajectories_data import get_trajectory_dataloader"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Config ===\n",
    "checkpoint_dir = \"trainings/models_DenseNet_cifar10\"\n",
    "ae_save_path = \"ae_models/ae_model_densenet.pt\"\n",
    "latent_dim = 2\n",
    "num_layers = 3\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "lr = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "1c6c114679050712",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class FlatTensorDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor = torch.load(self.file_paths[idx], map_location='cpu')\n",
    "        if self.transform:\n",
    "            tensor = self.transform(tensor)\n",
    "        return tensor\n",
    "\n",
    "def calculate_mean_std_flat(file_paths):\n",
    "    weights = [torch.load(fp, map_location='cpu') for fp in file_paths]\n",
    "    stacked = torch.stack(weights)\n",
    "    mean = torch.mean(stacked, dim=0)\n",
    "    std = torch.std(stacked, dim=0)\n",
    "    return mean, std\n",
    "\n",
    "from NeuroVisualizer.neuro_aux.trajectories_data import NormalizeModelParameters, ModelParamsDataset\n",
    "\n",
    "def get_trajectory_dataloader_flat(pt_files, batch_size, normalize=True, shuffle=True):\n",
    "    mean, std = calculate_mean_std_flat(pt_files)\n",
    "    normalizer = NormalizeModelParameters(mean, std)\n",
    "    dataset = FlatTensorDataset(pt_files, transform=normalizer if normalize else None)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle), normalizer"
   ],
   "id": "fcff69fa572664be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Load flattened checkpoints ===\n",
    "pt_files = get_files(checkpoint_dir, prefix=\"model-\")\n",
    "loader, transform = get_trajectory_dataloader_flat(pt_files, batch_size)"
   ],
   "id": "e434272482c0c81f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Get input dimension from one sample ===\n",
    "input_dim = loader.dataset[0].shape[0]"
   ],
   "id": "b55b24d2366ef0bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.load(pt_files[21])\n",
    "print(x.shape, x.numel(), x.dtype)"
   ],
   "id": "e49e96cdbab1450c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Init AE ===\n",
    "ae = UniformAutoencoder(input_dim, num_of_layers=num_layers, latent_dim=latent_dim).to(device)\n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()"
   ],
   "id": "9a7f20b8c6a7df6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === AE Training Loop ===\n",
    "for epoch in range(num_epochs):\n",
    "    ae.train()\n",
    "    total_loss = 0\n",
    "    for x in loader:\n",
    "        x = x.to(device)\n",
    "        x_recon, _ = ae(x)\n",
    "        loss = loss_fn(x_recon, x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1:03d} | Loss: {total_loss / len(loader):.6f}\")"
   ],
   "id": "9ef313f936002573",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Save AE Model ===\n",
    "os.makedirs(os.path.dirname(ae_save_path), exist_ok=True)\n",
    "torch.save(ae.state_dict(), ae_save_path)\n",
    "print(f\"AE model saved to {ae_save_path}\")"
   ],
   "id": "ca77147c81b9773",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
