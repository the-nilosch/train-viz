{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f7f75fb0f0a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T09:49:04.670789Z",
     "start_time": "2025-08-11T09:48:53.440210Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aad4dca1135c1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T09:49:16.101312Z",
     "start_time": "2025-08-11T09:49:04.672748Z"
    }
   },
   "outputs": [],
   "source": [
    "import phate, m_phate, umap # Should throw no error in proper environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c0d1b730f7f98",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Embedding Visualization TODOs\n",
    "Data\n",
    "- [x] PCA\n",
    "- [ ] Use ALL train data for PCA?\n",
    "- [x] PCA Denoising eval on denoised Embedding drift\n",
    "\n",
    "- [x] t-SNE\n",
    "- [ ] Visualize t-SNE training Steps\n",
    "- [ ] Refine with new paper\n",
    "\n",
    "- [x] UMAP\n",
    "- [x] UMAP Parameters\n",
    "\n",
    "- [x] Copy PHATE stuff\n",
    "- [x] Evaluate\n",
    "\n",
    "Visualization\n",
    "- [x] Live during training\n",
    "- [x] 3D\n",
    "- [x] With trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a718503b0efeb06",
   "metadata": {},
   "source": [
    "**Environment:** Please use another environment (`phate-env`) here\n",
    "\n",
    "# Embedding Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0a026-ac3e-4a6e-b44f-eb8951f926ca",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1112d-2e44-4e2d-a3c1-447bb79e76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== MNIST ========\n",
    "dataset = \"mnist\"\n",
    "\n",
    "run_id = \"run-0011-CNN_mnist_32_0.9776\"\n",
    "#run_id = \"run-0012-CNN_mnist_32_0.9768\"\n",
    "#run_id = \"run-0013-CNN_mnist_32_0.9797\"\n",
    "#run_id = \"run-0014-CNN_mnist_32_0.9744\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f267def576c812a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ==== CIFAR 10 ========\n",
    "dataset = \"cifar10\"\n",
    "\n",
    "# Residual\n",
    "run_id = \"run-0016-CNN_cifar10_128_0.8093\" # Seed 42, SAM\n",
    "# run_id = \"run-0018-CNN_cifar10_128_0.8499\" # Seed 42\n",
    "# run_id = \"run-0020-CNN_cifar10_128_0.8079\" # Seed 11, SAM\n",
    "# run_id = \"run-0022-CNN_cifar10_128_0.8519\" # Seed 11\n",
    "    \n",
    "# No Residual\n",
    "# run_id = \"run-0017-CNN_cifar10_128_0.8072\" # Seed 42, SAM\n",
    "# run_id = \"run-0019-CNN_cifar10_128_0.8487\" # Seed 42\n",
    "# run_id = \"run-0021-CNN_cifar10_128_0.8054\" # Seed 11, SAM\n",
    "# run_id = \"run-0023-CNN_cifar10_128_0.8509\" # Seed 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924209a2-02d3-4dd8-a8c6-3996fe5bfb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.visualization import Run\n",
    "run = Run(run_id, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aed3bbcc1aedeb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Recap: The Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e497128-2509-4772-a562-374b9b5f4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = run.plot_training_records()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e326d911ef3fe7",
   "metadata": {},
   "source": [
    "### Confusion Matrix Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999c2bbd1e40c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%matplotlib widget\n",
    "_ = run.confusion_matrix(annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c32f851085c59",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Embedding Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53098eaf37b86e9b",
   "metadata": {},
   "source": [
    "The evaluation measure in this work\n",
    "- **Multi-scale skips**: for each snapshot index `i`, compare its embedding `E_i` to earlier snapshots `E_{i - 2**n}` for `n = 0,1,…,4` (skip lengths 1, 2, 4, 8, 16).\n",
    "- **Mean Euclidean distance**:\n",
    "  ```python\n",
    "  drift = np.linalg.norm(current_snapshot - previous_snapshot, axis=1).mean()\n",
    "- **Result:** a dict mapping each skip length to a time series of drift values, showing how rapidly—and at what scales—the embedding space is evolving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fb8b2b-2c9f-4e53-8cb1-cf15d83366ee",
   "metadata": {},
   "source": [
    "With euclidean distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74f4a6-0298-482e-a879-66ec747ed2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run.plot_embedding_drifts() #(y_lim=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8d6c637a1d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run.plot_embedding_drift_multi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba24fab-3cfb-419f-99be-cd4417c72450",
   "metadata": {},
   "source": [
    "#### Manhattan distance\n",
    "The Manhattan distance, compared to the (scaled) Euclidean distance is **almost the same**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d4147-150b-41ce-b008-8781b0662371",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.plot_embedding_drifts_manhattan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9c76f-5468-4dc7-8783-41502aad6e2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CKA Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d1388-9730-48d1-93e1-1423ee9318cb",
   "metadata": {},
   "source": [
    "This plot shows **1 − CKA similarity** over time, representing the **structural change** in the embedding space.\n",
    "Lower values indicate high similarity (stable structure), while higher values reflect greater representational drift.\n",
    "It allows direct comparison with Euclidean embedding drift and helps identify when and how much the internal structure evolves during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16d17a-5cd7-43cb-971e-ad6e8b8b0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.plot_cka_similarities(y_lim=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf3d91-0424-4a9c-aae5-34b0f402fa87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Eigenvalue development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf064be8-890c-42e7-9feb-ffe93c885474",
   "metadata": {},
   "source": [
    "This plot shows the **10 top PCA eigenvalues** of the embedding space over training time.\n",
    "Each curve represents the variance explained by a principal direction.\n",
    "Changes in the eigenvalue spectrum reveal how the dimensional structure of the embeddings evolves — e.g., early compression, later expansion, or stabilization of representational capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f05cb0e-f47a-4ed3-ba61-db0431473459",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.eigenvalues(figsize=(8, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc744a-15a3-460c-958f-a53450207f92",
   "metadata": {},
   "source": [
    "### Mean Trajectory Curvature\n",
    "This plot shows the mean trajectory curvature of sample embeddings over training time, with shaded bands indicating ±1 standard deviation across samples.\n",
    "\n",
    "In the early epochs, curvature is relatively low, indicating smooth and directional changes in the embedding space. Later, the curvature rises and stabilizes in a higher range (~1.5–2.5 radians), suggesting that sample trajectories become increasingly erratic and less coherent.\n",
    "\n",
    "This indicates that the model transitions from a stable learning phase into a regime where embeddings frequently change direction, reflecting either ongoing internal restructuring, unstable optimization, or lack of convergence in representation space. The high standard deviation shows that this behavior is not uniform across samples, with some embeddings changing more drastically than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9732c42-820c-4aef-b514-d4041ae5d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.plot_curvature_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbd2ae9-66b7-4acd-abf2-d12a28a3699b",
   "metadata": {},
   "source": [
    "# Visualizations PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586398d0-0cdf-4e75-9e5b-2c6c644d7600",
   "metadata": {},
   "source": [
    "### PCA visualizations can be based on different bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f60595-3b4b-4519-b6bb-f2903735f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.visualization import generate_pca_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdfdc0a0d65a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_pca_first = generate_pca_animation(run, fit_basis='first')\n",
    "ani_pca_last = generate_pca_animation(run, fit_basis='last')\n",
    "ani_pca_all = generate_pca_animation(run, fit_basis='all')\n",
    "ani_pca_window = generate_pca_animation(run, fit_basis='window', window_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e0255-ab84-48c2-b36a-ddb502330086",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5ba29922f8e9aa",
   "metadata": {},
   "source": [
    "The 2D visualization here has a slider for epochs. You can also press Play, Pause and Stop\n",
    "\n",
    "Optionally, a translation between the noisy steps can be activated to better track points moving far distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766afd2-ce94-40f6-85c5-6a975534f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR100 Legend\n",
    "from helper.plots import show_cifar100_legend\n",
    "if dataset == \"cifar100\":\n",
    "    show_cifar100_legend(cmap = \"tab20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb2d03-069a-44f7-9723-c0548a13735a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%matplotlib widget\n",
    "from helper.visualization import show_animations\n",
    "\n",
    "show_animations(\n",
    "    animations=[ani_pca_first, ani_pca_last, ani_pca_all, ani_pca_window],\n",
    "    interpolate=False, # TRANSLATION via linear interpolation\n",
    "    steps_per_transition=2, # interpolation steps\n",
    "    figsize_per_plot=(4, 4),\n",
    "    alpha=0.8,\n",
    "    dot_size=6, # 12\n",
    "    cols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890550e8-bb38-4b21-b9b8-e53ef0947f26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    animations=[ani_pca_first, ani_pca_last, ani_pca_all, ani_pca_window],\n",
    "    figsize_per_plot=(4, 4),\n",
    "    add_confusion_matrix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427692c-4b5f-45f8-9a48-2f2046716f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ani_pca_window.save_as_gif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a7ed8-ceb6-4d73-94ec-c6cff458c4b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ani_pca_first.evaluate()\n",
    "ani_pca_last.evaluate()\n",
    "ani_pca_all.evaluate()\n",
    "ani_pca_window.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa99fb4-ed7c-47cd-b605-920168fb107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%matplotlib widget\n",
    "ani_pca_all.scatter_movements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c44fa5-4a4f-4c6b-b06e-869a61a166df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_pca_all.evaluate_movements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44191e4a-0010-4d18-9f07-f3ad26fe59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_pca_window.evaluate_movements()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aec985-8b62-40d1-ac21-7eecf80bf624",
   "metadata": {},
   "source": [
    "### Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d090eb840086dac",
   "metadata": {},
   "source": [
    "As the embedding snapshots during training are made within one epoch at fixed, but arbitrary intervals, with varying samples and potentially augmented images, they are very noisy.\n",
    "\n",
    "As a result, the values can only be seen as an indicator, not as an exact measurement of the embedding.\n",
    "\n",
    "Therefore, we can apply denoising to get a better overall picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a48d308f475df6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ani_pca_first_denoised = ani_pca_first.denoise(window_size=15, blend=0.9, mode='window', do_embedding_drift=False, do_cka_similarities=False)\n",
    "ani_pca_last_denoised = ani_pca_last.denoise(window_size=15, blend=0.9, mode='window', do_embedding_drift=False, do_cka_similarities=False)\n",
    "ani_pca_all_denoised = ani_pca_all.denoise(window_size=15, blend=0.9, mode='window', do_embedding_drift=False, do_cka_similarities=False)\n",
    "ani_pca_window_denoised = ani_pca_window.denoise(window_size=15, blend=0.9, mode='window', do_embedding_drift=False, do_cka_similarities=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f32db6-2327-4447-9c7b-0dfdd9c97cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_pca_window_denoised.plot(\n",
    "    interpolate=True,\n",
    "    steps_per_transition=1,\n",
    "    alpha=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e852934-5ddf-4f7d-801e-3b076855d3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    animations=[\n",
    "        ani_pca_first_denoised,\n",
    "        ani_pca_last_denoised,\n",
    "        ani_pca_all_denoised,\n",
    "        ani_pca_window_denoised],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c6ff0-740e-4572-8701-87e29778428c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ani_pca_all_denoised.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf74de08-bf1a-4877-ab1d-d58045627011",
   "metadata": {},
   "source": [
    "#### Now compared to denoised Embeddings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e11eda-0d32-4854-ab08-feac9e263081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ani_pca_first_denoised = ani_pca_first.denoise(window_size=15, blend=0.9, mode='window', do_embedding_drift=True)\n",
    "ani_pca_last_denoised = ani_pca_last.denoise(window_size=15, blend=0.9, mode='window', do_embedding_drift=True)\n",
    "ani_pca_all_denoised = ani_pca_all.denoise(window_size=15, blend=0.9, mode='window', do_embedding_drift=True)\n",
    "ani_pca_window_denoised = ani_pca_window.denoise(window_size=15, blend=0.9, mode='window', do_embedding_drift=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988cd7ece0328c9a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ani_pca_first_denoised.evaluate()\n",
    "ani_pca_last_denoised.evaluate()\n",
    "ani_pca_all_denoised.evaluate()\n",
    "ani_pca_window_denoised.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b64de-d0b6-4e6f-b530-7d7ed7f308f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_pca_all.evaluate_movements()\n",
    "ani_pca_all_denoised.evaluate_movements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0d664-a10a-45bd-ae27-bd0ca76596d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_pca_window.evaluate_movements()\n",
    "ani_pca_window_denoised.evaluate_movements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c08f1-10a9-472c-b8e3-742a70e0d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close interactivity of plots before\n",
    "matplotlib.pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af0580-dd6e-4f11-8cc2-2d5d8091cd33",
   "metadata": {},
   "source": [
    "### 3D\n",
    "We can also visualize 3D..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2fd49-c26e-43c9-afd2-91cc05c0f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_3D = generate_pca_animation(\n",
    "    run,\n",
    "    fit_basis='window',\n",
    "    out_dim=3 #3D\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28edfc-7d92-4e26-bc83-2f7be805a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_3D = animation_3D.denoise(do_embedding_drift=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f138d-0ddf-4d4c-a13e-d378ab10a54f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helper.plots import show_with_slider_3d\n",
    "\n",
    "show_with_slider_3d(\n",
    "    animation_3D.projections,\n",
    "    labels=animation_3D.labels,\n",
    "    interpolate=False,\n",
    "    steps_per_transition=1,\n",
    "    alpha=0.7,\n",
    "    dataset=animation_3D.run.dataset,\n",
    "    show_legend=False,\n",
    "    dot_size=10, #20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b47a57-efe1-4788-9960-b806a0f54483",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_3D.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb32e30-aa2d-46c1-8c95-33b5c6a1a0b1",
   "metadata": {},
   "source": [
    "### Other Denoising Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a4b616-b51b-4cb8-b80b-f7adda205f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#projections = projections_pca_window\n",
    "animation = ani_pca_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d75f8-b0e0-475f-86c3-53fc1c70ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee65e1-8146-4fb1-82ea-c5470c700ea0",
   "metadata": {},
   "source": [
    "To smooth the low-dimensional projections we use two denoising modes:\n",
    "\n",
    "- **Exponential (causal) blending**  \n",
    "  Recursively mix each frame $P_i$ with the previous denoised output $D_{i-1}$:  \n",
    "  $$D_i = (1-\\alpha)\\,P_i + \\alpha\\,D_{i-1}$$  \n",
    "  Reacts quickly while damping high-frequency noise.\n",
    "\n",
    "- **Window (moving-average) blending**  \n",
    "  Compute the mean of the last $w$ raw projections:  \n",
    "  $$\\overline{P}_i = \\frac{1}{w}\\sum_{j=i-w+1}^{i}P_j$$  \n",
    "  and blend it with $P_i$:  \n",
    "  $$D_i = (1-\\alpha)\\,P_i + \\alpha\\,\\overline{P}_i$$\n",
    "  Uses surrounding frames for stronger smoothing at the cost of lag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462f544-dc07-437e-a044-bd7d2970f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_window = animation.denoise(window_size=15, blend=0.9, mode='window')\n",
    "denoised_exponential = animation.denoise(blend=0.8, mode='exponential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c6690f7a02cbc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    animations=[\n",
    "        animation,\n",
    "        denoised_window,\n",
    "        denoised_exponential],\n",
    "    custom_titles=[\"PCA\", \"PCA denoised window\", \"PCA denoised exponential\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d9be1-59e3-4d1d-8575-836d67857a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_window.evaluate()\n",
    "denoised_exponential.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a0dd8-c141-4c2c-9ffa-674bbd8146e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define parameters\n",
    "window_sizes = [1, 2, 4, 8, 10, 15, 20, 30]\n",
    "blend_values = np.linspace(0, 1, 11)\n",
    "correlation_results = {ws: [] for ws in window_sizes}\n",
    "exponentials = []\n",
    "\n",
    "# Run correlations\n",
    "for blend in blend_values:\n",
    "    for ws in window_sizes:\n",
    "        corr = animation.denoise(window_size=ws, blend=blend, mode='window').evaluate(verbose=False)\n",
    "        correlation_results[ws].append(corr)\n",
    "\n",
    "    corr = animation.denoise(blend=blend, mode='exponential').evaluate(verbose=False)\n",
    "    exponentials.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2ac73-acf6-4edc-93fa-eef1f0dd3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(8, 4))\n",
    "for ws in window_sizes:\n",
    "    plt.plot(blend_values, correlation_results[ws], label=f'window_size={ws}')\n",
    "plt.plot(blend_values, exponentials, label=f'exponential', linewidth=3)\n",
    "plt.xlabel(\"Blend\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.title(\"Correlation vs. Blend for different denoise calculations\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd96e10-327c-41d4-bad2-cc191c546db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "window_sizes = range(1, 30)\n",
    "correlation_results = []\n",
    "blend = 0.9\n",
    "\n",
    "# Run correlations\n",
    "for ws in window_sizes:\n",
    "    corr = animation.denoise(window_size=ws, blend=blend, mode='window').evaluate(verbose=False)\n",
    "    correlation_results.append(corr)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(window_sizes, correlation_results)\n",
    "plt.xlabel(\"Window Size\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.title(\"Correlation vs. Window Size\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e7fb1-b764-4e82-8636-740d1d0bb4b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# t-SNE Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b6ba7-2a11-4c80-a147-b7cc15826337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close interactivity of plots before\n",
    "matplotlib.pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719776e-ec14-411d-af3c-0817e0afea58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Standard t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249ba00-2adc-471b-89ee-b6be8e2ddd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore original values\n",
    "#run = Run(run_id, dataset)\n",
    "#run.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5964f2-c256-4e59-b61b-6e7f82d28128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE is computationally very intense\n",
    "#run.subsample(point_step=5, snapshot_step=1)\n",
    "#run.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabca50f-6ed6-46e4-9025-0e271e143a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a comparison\n",
    "from helper.visualization import  generate_pca_animation\n",
    "pca_animation = generate_pca_animation(run, fit_basis='all').denoise(blend=0.8, mode='exponential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a7c6a-4a82-4bb4-8ae2-7c67d3cc223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.visualization import generate_tsne_animation, show_animations\n",
    "\n",
    "tsne_animation = generate_tsne_animation(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e3c83-35e9-4133-8c5c-18dfdfeb8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%matplotlib widget\n",
    "\n",
    "show_animations(\n",
    "    [tsne_animation, pca_animation],\n",
    "    interpolate=True,\n",
    "    steps_per_transition=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0dd05f-88e8-46e0-a5f4-056ccf2ddaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_animation.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d444a-2e88-4906-8b19-c79c5652c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne_animation.save_as_gif(frame_interval=100, steps_per_transition=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea932b-041b-4447-961d-e1c215772c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_tsne = tsne_animation.denoise(blend=0.8, mode='exponential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a115049-8ef5-479e-afb2-5b3b87766ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations([tsne_animation, denoised_tsne, pca_animation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce924bba-7cff-41d5-a92b-4ebaba98ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_tsne.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdb5d9-0a90-4bbd-a335-2b86fa1affd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.visualization import show_projections_and_drift\n",
    "\n",
    "show_animations([pca_animation, denoised_tsne, tsne_animation], with_drift=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b28def-b1d3-4d8a-b5d7-db35444f2e7b",
   "metadata": {},
   "source": [
    "## t-SNE with update blending\n",
    "\n",
    "After computing t-SNE for frame $i$, you blend it with the previous projection.\n",
    "`tsne_update` is a weight in $[0,1]$:\n",
    "- If `tsne_update=1`, it's exactly the original method (no blending).\n",
    "- If `tsne_update=0`, you freeze to the previous frame (no update at all).\n",
    "- Values like `0.2 - 3` should result in a smooth interpolation between old and new.\n",
    "\n",
    "Result: Extra smoothing over time.\n",
    "- Avoids too fast movements\n",
    "- Avoids flips of dense clusters\n",
    "- Can introduce lag or “stickiness,” but animations look steadier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467abb76-dc7e-4d9e-800a-21c1ce7ee54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_avg = generate_tsne_animation(\n",
    "    run,\n",
    "    tsne_update=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad878e-d1db-44f7-bedc-008357c08d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    [tsne_avg, tsne_animation],\n",
    "    #interpolate=True,\n",
    "    #steps_per_transition=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00bfbb-b9a7-4f1b-97b0-1983f20d6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise the evaluation\n",
    "tsne_avg.denoise(do_projections=False, blend=0.7, mode='exponential').evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e18984c-af0a-4bbd-8bbe-f2634b354c33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## t-SNE with backwards computation\n",
    "Starts with the last frame\n",
    "- Ensures convergence\n",
    "- Improves noise in early frames as the basis is from a later and better picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4102405-6591-4e94-8650-25f27b4734c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_reverse = generate_tsne_animation(\n",
    "    run,\n",
    "    reverse_computation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e7e8a6-76a1-49a8-bb4b-d4a16efed77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    [tsne_reverse, tsne_animation],\n",
    "    interpolate=True,\n",
    "    steps_per_transition=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb05c3-55c6-4b7b-8e98-f32742883527",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_reverse_2 = generate_tsne_animation(\n",
    "    run,\n",
    "    reverse_computation=True,\n",
    "    tsne_update=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5461e81-72b8-41da-a9d5-4f8405fa9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    [tsne_reverse_2, tsne_reverse, tsne_animation],\n",
    "    interpolate=True,\n",
    "    steps_per_transition=5,\n",
    "    #with_drift=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd19a9-e98e-49d9-95ad-2a4d668a2def",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_reverse.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fadc601-22ed-432e-94f3-425daff5efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_reverse_2.denoise(do_projections=False, blend=0.7, mode='exponential').evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927e45b-59ed-4957-8e9b-825b894c54b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## t-SNE with Cosine metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ae282-43de-4dc9-b133-09f43f46b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_cosine = generate_tsne_animation(\n",
    "    run,\n",
    "    tsne_update=0.2,\n",
    "    metric='cosine'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c87fc4-8bd0-4d7a-89a9-0251917cd9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    [tsne_cosine, tsne_avg],\n",
    "    interpolate=True,\n",
    "    steps_per_transition=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54057401-c596-47a1-93db-b124e7306914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_projections_and_drift(\n",
    "    projections_list = [tsne_cosine, tsne_animation],\n",
    "    interpolate=True,\n",
    "    steps_per_transition=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ceeea-c65b-49fc-b631-0b0833161724",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_cosine.denoise(do_projections=False, blend=0.7, mode='exponential').evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b42e1-8925-4597-b53c-5726e985239b",
   "metadata": {},
   "source": [
    "## t-SNE with random Seed\n",
    "Doesen't affect animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5b0b4-e5ec-4f15-a90f-c103a9d77217",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_random = generate_tsne_animation(\n",
    "    run,\n",
    "    random_state=1106,\n",
    "    tsne_init='random'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c866c99-9f5f-4f78-92d7-484d1ae6e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    [tsne_random, tsne_animation],\n",
    "    interpolate=True,\n",
    "    steps_per_transition=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab36d8-1d68-44e1-a7ae-7db893dadc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_random.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe4a13-74bf-439e-8be9-7568a9ec1e66",
   "metadata": {},
   "source": [
    "## t-SNE Perplexity\n",
    "Compare 5 - 10 - 30 - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132def5-0a59-4c1b-be21-c502e75c5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_p_5 = generate_tsne_animation(run, tsne_perplexity=5, metric='cosine')\n",
    "tsne_p_10 = generate_tsne_animation(run, tsne_perplexity=10, metric='cosine')\n",
    "tsne_p_30 = generate_tsne_animation(run, tsne_perplexity=30, metric='cosine')\n",
    "tsne_p_50 = generate_tsne_animation(run, tsne_perplexity=50, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691030b6-4e82-463f-9176-ce7c679a96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    [\n",
    "        tsne_p_5,\n",
    "        tsne_p_10,\n",
    "        tsne_p_30,\n",
    "        tsne_p_50\n",
    "    ],\n",
    "    custom_titles=[\n",
    "        \"t-SNE Perplexity 5\",\n",
    "        \"t-SNE Perplexity 10\",\n",
    "        \"t-SNE Perpl. 30 (standard)\",\n",
    "        \"t-SNE Perplexity 50\"\n",
    "    ],\n",
    "    shared_axes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2abbe99-489c-4ffb-8148-9a116a277d88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dynamic t-SNE\n",
    "This is an implementation of Rauber et. al.\n",
    "https://github.com/paulorauber/thesne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4b7bd-937a-4d05-bec8-2ef18ccc229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "\n",
    "\n",
    "class DynamicTSNE:\n",
    "    def __init__(\n",
    "            self,\n",
    "            output_dims=2,\n",
    "            verbose=True,\n",
    "    ):\n",
    "        self.output_dims = output_dims\n",
    "        self.verbose = verbose\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def compute_affinities(self, Xs, perplexity=30.0, k_neighbors=90):\n",
    "        def Hbeta(D, beta):\n",
    "            P = torch.exp(-D * beta)\n",
    "            sumP = torch.sum(P)\n",
    "            sumP = torch.clamp(sumP, min=1e-8)\n",
    "            H = torch.log(sumP) + beta * torch.sum(D * P) / sumP\n",
    "            P = torch.clamp(P / sumP, min=1e-8)\n",
    "            return H, P\n",
    "\n",
    "        def compute_P(X, init_beta=None):\n",
    "            t0 = time.time()\n",
    "\n",
    "            n = X.shape[0]\n",
    "            D = torch.cdist(X, X, p=2).pow(2)\n",
    "            P = torch.zeros((n, n), device=X.device)\n",
    "            beta = init_beta.clone() if init_beta is not None else torch.ones(n, device=X.device)\n",
    "            logU = torch.log(torch.tensor(perplexity, device=X.device))\n",
    "            all_tries = 0\n",
    "\n",
    "            for i in range(n):\n",
    "                distances = D[i]\n",
    "                topk = torch.topk(distances, k=k_neighbors + 1, largest=False)\n",
    "                idx = topk.indices[topk.indices != i][:k_neighbors]\n",
    "                Di = torch.clamp(distances[idx], max=1e3)\n",
    "\n",
    "                betamin, betamax = None, None\n",
    "                H, thisP = Hbeta(Di, beta[i])\n",
    "                tries = 0\n",
    "                while torch.abs(H - logU) > 1e-5 and tries < 50:\n",
    "                    if H > logU:\n",
    "                        betamin = beta[i].clone()\n",
    "                        beta[i] = beta[i] * 2 if betamax is None else (beta[i] + betamax) / 2\n",
    "                    else:\n",
    "                        betamax = beta[i].clone()\n",
    "                        beta[i] = beta[i] / 2 if betamin is None else (beta[i] + betamin) / 2\n",
    "                    H, thisP = Hbeta(Di, beta[i])\n",
    "                    tries += 1\n",
    "                all_tries += tries\n",
    "                P[i, idx] = thisP\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"Total affinity computation time: {time.time() - t0:.2f}s, {all_tries / n} Tries\")\n",
    "\n",
    "            P = (P + P.T) / (2 * n)\n",
    "            return P, beta\n",
    "\n",
    "        X_tensor = [torch.tensor(X, device=self.device) for X in Xs]\n",
    "        self.Xs = X_tensor\n",
    "\n",
    "        Ps = []\n",
    "        prev_beta = None\n",
    "        for X in X_tensor:\n",
    "            P, prev_beta = compute_P(X, prev_beta)\n",
    "            Ps.append(P)\n",
    "\n",
    "        self.Ps = torch.stack(Ps)\n",
    "        assert not torch.isnan(self.Ps).any(), \"Affinity matrix has NaN\"\n",
    "\n",
    "    def fit(self, n_epochs=1000, exaggeration=12.0, exaggeration_epochs=250, lr=200.0, lambd=0.1):\n",
    "        T = len(self.Xs)\n",
    "        n = self.Xs[0].shape[0]\n",
    "\n",
    "        Y_init = []\n",
    "        for X in self.Xs:\n",
    "            X_cpu = X.detach().cpu().numpy()\n",
    "            pca = PCA(n_components=self.output_dims)\n",
    "            Y_pca = pca.fit_transform(X_cpu)\n",
    "            Y_init.append(torch.tensor(Y_pca, device=self.device, dtype=torch.float32))\n",
    "        \n",
    "        Y = torch.stack(Y_init)\n",
    "        Y.requires_grad_()\n",
    "\n",
    "        optimizer = Adam([Y], lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            total_loss = 0\n",
    "\n",
    "            if epoch < exaggeration_epochs:\n",
    "                P_use = self.Ps * exaggeration\n",
    "            else:\n",
    "                lambd = 0\n",
    "                P_use = self.Ps\n",
    "            \n",
    "            for t in range(T):\n",
    "                Qt, _ = self._compute_lowdim_affinities(Y[t])\n",
    "                loss = self._kl_divergence(P_use[t], Qt)\n",
    "                if t > 0:\n",
    "                    loss += (lambd / (2 * n)) * F.mse_loss(Y[t], Y[t - 1])\n",
    "                total_loss += loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_([Y], max_norm=10.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if self.verbose and (epoch % 100 == 0 or epoch == n_epochs - 1):\n",
    "                print(f\"Epoch {epoch}, Loss: {total_loss.item():.4f}\")\n",
    "\n",
    "        return [Y[t].detach().cpu().numpy() for t in range(T)]\n",
    "\n",
    "    def _compute_lowdim_affinities(self, Y):\n",
    "        num = 1 / (1 + torch.cdist(Y, Y, p=2).pow(2))\n",
    "        num.fill_diagonal_(0.0)\n",
    "        Q = torch.clamp(num / num.sum(), min=1e-5)\n",
    "        return Q, num\n",
    "\n",
    "    def _kl_divergence(self, P, Q):\n",
    "        return torch.sum(P * torch.log((P + 1e-8) / (Q + 1e-8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a3a48-ea63-4147-9070-9a2f42a480d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = DynamicTSNE()\n",
    "tsne.compute_affinities(run.embeddings, perplexity=5.0, k_neighbors=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaef59e-6776-4280-ae6e-f68dd26a20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "projections = tsne.fit(lr=200, lambd=0.1, n_epochs=1000, exaggeration_epochs=250, exaggeration=22.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866586b-984f-4a92-af2d-1a5a09e8d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from helper.plots import show_with_slider\n",
    "\n",
    "show_with_slider(\n",
    "    projections,\n",
    "    labels=run.labels,\n",
    "    interpolate=True,\n",
    "    steps_per_transition=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad151f-e036-4669-b509-eb62b62501d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b29f3b-4b40-4572-8c3d-8bda54d0ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_drift_vs_embedding_drift(projections, run.embedding_drifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e59b0e-c6fb-4a4b-a4a9-9b595fee710b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MODERN DYNAMIC TNSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb1297-f353-4fa2-96d7-22342e02c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "modern_dynamic_tsne = ModernDynamicTSNE(\n",
    "    n_epochs=500,\n",
    "    perplexity=50,\n",
    ")\n",
    "projections_3 = modern_dynamic_tsne.fit_transform(run.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7196e94-dedb-45b4-bc46-425fff09adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.plots import show_multiple_projections_with_slider\n",
    "\n",
    "show_multiple_projections_with_slider(\n",
    "    projections_list=[tsne_p_5_blend.projections, projections_3],\n",
    "    labels=run.labels,\n",
    "    titles=[\"t-SNE\", \"Dynamic t-SNE\"],\n",
    "    interpolate=False,\n",
    "    figsize_per_plot=(4, 4),\n",
    "    dataset=dataset,\n",
    "    shared_axes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5e23f-6ac4-4994-9ca5-438e3c98fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "\n",
    "\n",
    "class ModernDynamicTSNE:\n",
    "    def __init__(\n",
    "        self,\n",
    "        perplexity=30,\n",
    "        n_epochs=1000,\n",
    "        output_dims=2,\n",
    "        initial_lr=2400,\n",
    "        final_lr=200,\n",
    "        lr_switch=250,\n",
    "        init_stdev=1e-4,\n",
    "        initial_momentum=0.5,\n",
    "        final_momentum=0.8,\n",
    "        momentum_switch=250,\n",
    "        lmbda=0.0,\n",
    "        sigma_iters=50,\n",
    "        verbose=True,\n",
    "        device=None\n",
    "    ):\n",
    "        self.perplexity = perplexity\n",
    "        self.n_epochs = n_epochs\n",
    "        self.output_dims = output_dims\n",
    "        self.initial_lr = initial_lr\n",
    "        self.final_lr = final_lr\n",
    "        self.lr_switch = lr_switch\n",
    "        self.init_stdev = init_stdev\n",
    "        self.initial_momentum = initial_momentum\n",
    "        self.final_momentum = final_momentum\n",
    "        self.momentum_switch = momentum_switch\n",
    "        self.lmbda = lmbda\n",
    "        self.sigma_iters = sigma_iters\n",
    "        self.verbose = verbose\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def _hbeta(self, D, beta):\n",
    "        P = torch.exp(-D * beta)\n",
    "        sumP = torch.sum(P)\n",
    "        sumP = torch.clamp(sumP, min=1e-8)\n",
    "        H = torch.log(sumP) + beta * torch.sum(D * P) / sumP\n",
    "        P = P / sumP\n",
    "        return H, P\n",
    "\n",
    "    def _binary_search_perplexity(self, D, tol=1e-5):\n",
    "        n = D.shape[0]\n",
    "        sigmas = torch.ones(n, device=self.device)\n",
    "        P = torch.zeros((n, n), device=self.device)\n",
    "\n",
    "        logU = np.log(self.perplexity)\n",
    "        for i in range(n):\n",
    "            betamin = None\n",
    "            betamax = None\n",
    "            beta = sigmas[i]\n",
    "            Di = D[i][torch.arange(n) != i]\n",
    "            H, thisP = self._hbeta(Di, beta)\n",
    "\n",
    "            tries = 0\n",
    "            while torch.abs(H - logU) > tol and tries < self.sigma_iters:\n",
    "                if H > logU:\n",
    "                    betamin = beta\n",
    "                    beta = beta * 2 if betamax is None else (beta + betamax) / 2\n",
    "                else:\n",
    "                    betamax = beta\n",
    "                    beta = beta / 2 if betamin is None else (beta + betamin) / 2\n",
    "                H, thisP = self._hbeta(Di, beta)\n",
    "                tries += 1\n",
    "            P[i, torch.arange(n) != i] = thisP\n",
    "        return (P + P.T) / (2 * n)\n",
    "\n",
    "    def _precompute_Ps(self, Xs):\n",
    "        Ps = []\n",
    "        for X in Xs:\n",
    "            D = torch.cdist(X, X).pow(2)\n",
    "            P = self._binary_search_perplexity(D)\n",
    "            Ps.append(P)\n",
    "        return Ps\n",
    "\n",
    "    def _compute_cost(self, Ys, Ps):\n",
    "        total_kl = 0\n",
    "        for Y, P in zip(Ys, Ps):\n",
    "            Q_num = 1 / (1 + torch.cdist(Y, Y).pow(2))\n",
    "            Q_num.fill_diagonal_(0)\n",
    "            Q = Q_num / Q_num.sum()\n",
    "            kl = torch.sum(P * torch.log((P + 1e-8) / (Q + 1e-8)))\n",
    "            total_kl += kl\n",
    "        smoothness = sum((Ys[i] - Ys[i + 1]).pow(2).sum() for i in range(len(Ys) - 1))\n",
    "        return total_kl + self.lmbda * smoothness / (2 * Ys[0].shape[0])\n",
    "\n",
    "    def fit_transform(self, Xs_np):\n",
    "        Xs = [torch.tensor(X, device=self.device, dtype=torch.float32) for X in Xs_np]\n",
    "        T = len(Xs)\n",
    "        N = Xs[0].shape[0]\n",
    "\n",
    "        # Init Ys with PCA\n",
    "        Ys = [\n",
    "            torch.tensor(PCA(n_components=self.output_dims).fit_transform(X.cpu().numpy()),\n",
    "                         device=self.device, dtype=torch.float32, requires_grad=True)\n",
    "            for X in Xs\n",
    "        ]\n",
    "\n",
    "        # Precompute all P matrices once\n",
    "        Ps = self._precompute_Ps(Xs)\n",
    "\n",
    "        optimizer = SGD(Ys, lr=self.initial_lr, momentum=self.initial_momentum)\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            if epoch == self.lr_switch:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = self.final_lr\n",
    "            if epoch == self.momentum_switch:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['momentum'] = self.final_momentum\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = self._compute_cost(Ys, Ps)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if self.verbose and (epoch % 100 == 0 or epoch == self.n_epochs - 1):\n",
    "                print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        return [Y.detach().cpu().numpy() for Y in Ys]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494dfc6-12d9-437e-aae0-35a578370440",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4dbc0c-eded-4313-943f-bd1887e209b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.utils.deprecation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37c846-6a78-4367-9d50-43d002fcc7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore original values\n",
    "#run = Run(run_id, dataset)\n",
    "#run.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7803be-dd8e-4b48-892f-0176fc1c77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.subsample(point_step=5, snapshot_step=5)\n",
    "#run.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b159b36e-6999-4185-b11c-e83e2c080709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.visualization import generate_pca_animation, generate_umap_animation\n",
    "\n",
    "pca_animation = generate_pca_animation(run, fit_basis='all', ).denoise(blend=0.8, mode='exponential')\n",
    "\n",
    "print(f\"{len(run.embeddings)} - 1 should be {len(run.embedding_drifts[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd223f54-fecc-4d6a-b85e-6672cef5db9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "umap_animation = generate_umap_animation(\n",
    "    run,\n",
    "    fit_basis='all_n', # 'all_n' includes every n-th embedding\n",
    "    fit_basis_n=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e30ba-9821-49e6-900c-0b3c5b203c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%matplotlib widget\n",
    "from helper.visualization import show_animations\n",
    "\n",
    "show_animations(\n",
    "    [\n",
    "        umap_animation,\n",
    "        pca_animation,\n",
    "    ],\n",
    "    shared_axes=False,\n",
    "    add_confusion_matrix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1556a9-8082-45c7-b04d-a541f691816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_animation.evaluate(y_lim=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208b4b4-daf8-422c-8e1c-a56b34f5856b",
   "metadata": {},
   "source": [
    "### UMAP Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf31ccc-ccf5-4a85-92ed-2d6e327da0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.subsample(point_step=5, snapshot_step=5)\n",
    "#run.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cbf93d-f865-4ead-826f-38156ae8fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current standard\n",
    "umap_ani = umap_animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcda4dd-8c58-4d9d-a5d9-6b1489b71cd7",
   "metadata": {},
   "source": [
    "#### Cosine Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608ce36-62eb-400b-8387-ea09131c6130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "umap_cosine = generate_umap_animation(\n",
    "    run,\n",
    "    metric='cosine'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5634d-7674-4dcb-9a37-e87c260e39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations([\n",
    "        umap_ani,\n",
    "        umap_cosine,\n",
    "    ], shared_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d3bc4-0883-4cb3-9f0c-436e7524f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_cosine.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4a6ef-ab9e-4ceb-aced-1aa4c022b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_ani.denoise().evaluate()\n",
    "umap_cosine.denoise().evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5bff2a-57dd-434b-ac11-36c77f9400ad",
   "metadata": {},
   "source": [
    "#### Number of Neighbors\n",
    "Local vs global structure\n",
    "\n",
    "This determines the number of neighboring points used in local approximations of manifold structure. Larger values will result in more global structure being preserved at the loss of detailed local structure. In general this parameter should often be in the range 5 to 50, with a choice of 10 to 15 being a sensible default. (From documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf93a6-95e3-4719-85b3-8a51f989e103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "umap_neighbors_5 = generate_umap_animation(\n",
    "    run,\n",
    "    metric='cosine',\n",
    "    fit_basis_n=10,\n",
    "    n_neighbors=5\n",
    ")\n",
    "umap_neighbors_15 = umap_cosine\n",
    "umap_neighbors_30 = generate_umap_animation(\n",
    "    run,\n",
    "    metric='cosine',\n",
    "    fit_basis_n=10,\n",
    "    n_neighbors=30\n",
    ")\n",
    "umap_neighbors_50 = generate_umap_animation(\n",
    "    run,\n",
    "    metric='cosine',\n",
    "    fit_basis_n=10,\n",
    "    n_neighbors=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c341f6-943b-40c1-b23f-7248d3724027",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_neighbors_30 = generate_umap_animation(\n",
    "    run,\n",
    "    metric='cosine',\n",
    "    fit_basis_n=10,\n",
    "    n_neighbors=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955b24a-1e35-4b2b-adc7-cc6f9ad43654",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%matplotlib widget\n",
    "from helper.visualization import show_animations\n",
    "\n",
    "show_animations(\n",
    "    [\n",
    "        umap_neighbors_5,\n",
    "        umap_neighbors_15,\n",
    "        umap_neighbors_30,\n",
    "        umap_neighbors_50,\n",
    "    ],\n",
    "    interpolate=True,\n",
    "    shared_axes=False,\n",
    "    cols=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7611b-e919-49bb-b6b6-f21d84497401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "umap_neighbors_15.evaluate()\n",
    "umap_neighbors_50.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6996c4-27a8-4c4a-8afa-cb1170424e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_n_05_denoised = umap_neighbors_5.denoise(window_size=15, blend=0.99, mode='window')\n",
    "umap_n_15_denoised = umap_neighbors_15.denoise(window_size=15, blend=0.99, mode='window')\n",
    "umap_n_50_denoised = umap_neighbors_50.denoise(window_size=15, blend=0.99, mode='window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb75e8-d20d-4d5b-bc65-2296b63387ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    [\n",
    "        umap_n_05_denoised,\n",
    "        umap_n_15_denoised,\n",
    "        umap_n_50_denoised,\n",
    "    ],\n",
    "    shared_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d400164f-dfa7-4a5e-a9f2-375ac71a7937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "umap_n_15_denoised.evaluate()\n",
    "umap_n_50_denoised.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f08286-1fb6-4c4e-9277-f2ccf6609a25",
   "metadata": {},
   "source": [
    "#### Min Dist\n",
    "This controls how tightly the embedding is allowed compress points together. Larger values ensure embedded points are more evenly distributed, while smaller values allow the algorithm to optimise more accurately with regard to local structure. Sensible values are in the range 0.001 to 0.5, with 0.1 being a reasonable default. (From documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba712fd5-8a39-4935-92a2-5e1ecaaac35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_dist_001 = generate_umap_animation(\n",
    "    run,\n",
    "    metric='cosine',\n",
    "    min_dist=0.001\n",
    ")\n",
    "umap_dist_01 = generate_umap_animation(\n",
    "    run,\n",
    "    metric='cosine',\n",
    "    min_dist=0.01\n",
    ")\n",
    "umap_dist_1 = umap_cosine\n",
    "umap_dist_5 = generate_umap_animation(\n",
    "    run,\n",
    "    metric='cosine',\n",
    "    min_dist=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc84371d-6813-42fd-875c-989f8fbeecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations([\n",
    "        umap_dist_001,\n",
    "        umap_dist_01,\n",
    "        umap_dist_1,\n",
    "        umap_dist_5\n",
    "    ], cols=4, shared_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28fd708-2d1a-4a93-8af8-dd93c4feb9a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "umap_dist_5.evaluate(y_lim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67ab0a-9fab-465d-9772-c98ffac92622",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_dist_5.denoise().evaluate(y_lim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17f39c1-ad9a-4e65-927f-afd715442e58",
   "metadata": {},
   "source": [
    "#### Educated Guess choice\n",
    "- Neighbors? ~15 shows best dynamics\n",
    "- Large min_dist [0.1, 0.5] reveals inner-cluster dynamics most\n",
    "- Cosine seems to emphasize different changes and builds different-shaped clusters - the Scores for Embedding and visualization drift are also better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b85ce6-a9f4-408e-8daa-4979ba96187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_cosine_n20 = generate_umap_animation(\n",
    "    run,\n",
    "    fit_basis='all_n',\n",
    "    n_neighbors=20,\n",
    "    metric='cosine',\n",
    "    min_dist=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81288fa6-d83b-4057-ba75-157b7f68798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    [\n",
    "        umap_cosine_n20,\n",
    "        umap_cosine,\n",
    "    ],\n",
    "    shared_axes=False,\n",
    "    add_confusion_matrix=True,\n",
    "    annotate_confusion_matrix=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b91ab-421e-451a-bb93-d5c9851c2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_cosine_n20.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12462063-12c3-461d-9358-a4c8d5a2ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_cosine_n20.denoise().evaluate(y_lim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae21008-fd10-4767-a0cf-03fa666ee8b7",
   "metadata": {},
   "source": [
    "# PHATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e556d-78f9-4bf9-bf1d-9f5e6919c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef0141-0970-43a3-8d1e-bda3741d0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sub = Run(run_id, dataset).subsample(point_step=5, snapshot_step=2).print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e0625-b79f-4e4a-91a6-5d8409e92549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_phate(\n",
    "        run: Run,\n",
    "        max_frames=None,\n",
    "        out_dim=2,\n",
    "        knn=5,\n",
    "        decay=40,\n",
    "        t=20,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        window=0  # number of frames before to include for fitting\n",
    "):\n",
    "    import phate\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "    from scipy.linalg import orthogonal_procrustes\n",
    "\n",
    "    embeddings_list = run.embeddings.copy()\n",
    "    max_frames = max_frames or len(embeddings_list)\n",
    "    projections = []\n",
    "\n",
    "    title = f'PHATE (knn={knn}, decay={decay}, t={t}, window={window})'\n",
    "\n",
    "    prev_projection = None\n",
    "\n",
    "    for i in tqdm(range(max_frames), desc=\"PHATE frames\"):\n",
    "        # Determine window range\n",
    "        start = max(0, i - window)\n",
    "        end = min(max_frames, i + 1)\n",
    "        fit_data = np.concatenate(embeddings_list[start:end], axis=0)\n",
    "\n",
    "        # Fit PHATE on the windowed data\n",
    "        phate_op = phate.PHATE(\n",
    "            n_components=out_dim,\n",
    "            knn=knn,\n",
    "            decay=decay,\n",
    "            t=t,\n",
    "            n_jobs=n_jobs,\n",
    "            random_state=random_state,\n",
    "            verbose=False\n",
    "        )\n",
    "        fit_projection = phate_op.fit_transform(fit_data)\n",
    "\n",
    "        # Extract just the projection for the current frame\n",
    "        current_len = len(embeddings_list[i])\n",
    "        offset = sum(len(embeddings_list[j]) for j in range(start, i))\n",
    "        projection = fit_projection[offset:offset + current_len]\n",
    "\n",
    "        # Flip and align using orthogonal Procrustes\n",
    "        if prev_projection is not None:\n",
    "            R, _ = orthogonal_procrustes(projection, prev_projection)\n",
    "            projection = projection @ R\n",
    "\n",
    "        projections.append(projection)\n",
    "        prev_projection = projection.copy()\n",
    "\n",
    "    return Animation(projections=projections, title=title, run=run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dcde80-4021-45cb-8cfb-56be2003a645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phate_animation = generate_phate(run_sub, knn=30, decay=50, t=30, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad2f0c-46be-4678-a7ec-d20772ec7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_animation.plot(interpolate=True, steps_per_transition=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e43b07-317e-4120-a33d-0905b27beeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_animation.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89445b-522a-47c1-a450-e2215f26abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#phate_animation.save_as_gif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cbc6f8-3a4f-45e9-818c-6ebf5df8c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_denoised = phate_animation.denoise(window_size=5, blend=0.99, mode='window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b10c9-bd59-4f32-8def-df67496871e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_denoised.plot(interpolate=True, steps_per_transition=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7797f98-ba68-44e5-86fd-5165ea79c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#phate_denoised.save_as_gif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7ecfe-943f-488c-bab9-bcf5ccf34fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_denoised.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf26f58-1caf-4ced-a34d-3db6baa3de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose Epoch e\n",
    "total_epochs = len(run.embeddings)\n",
    "e = 249\n",
    "\n",
    "emb = run.embeddings[e - 1]\n",
    "labels = run.labels[0] # [e-1] or [0] doesn't matter\n",
    "\n",
    "# Apply PHATE\n",
    "phate_op = phate.PHATE()\n",
    "emb_phate = phate_op.fit_transform(emb)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(emb_phate[:, 0], emb_phate[:, 1], c=labels, cmap='tab10', s=5)\n",
    "plt.title(f\"Epoch {e}/{total_epochs}: Embedding space colored by CIFAR10 class (PHATE)\")\n",
    "plt.colorbar(label=\"Class\")\n",
    "plt.show()\n",
    "\n",
    "# Takes ~ 5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12e753-004a-4139-9022-29ea9bb7ac70",
   "metadata": {},
   "source": [
    "### 2) Development of data points through epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4736056-ffc3-4bba-8576-e73d6b2d7f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helper.visualization import compute_mphate_embeddings, mphate_to_animation\n",
    "\n",
    "mphate_emb = compute_mphate_embeddings(run)\n",
    "# Takes ~10 min (scales on samples x epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cffd4b-79f8-4095-b158-31906940c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_phate_animation = mphate_to_animation(mphate_emb, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2beb7-6838-4b54-a2a6-7bd51c8f23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%matplotlib widget\n",
    "m_phate_animation.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d75fe-d748-49ae-be91-7e0713d718ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_phate_animation.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d9d10-d250-46fe-bcd2-e0c292f703b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_phate_denoised = m_phate_animation.denoise(window_size=20, blend=0.9, mode='window')\n",
    "#m_phate_denoised = m_phate_animation.denoise(blend=0.8, mode='exponential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7886d-ef48-4c92-9df6-890ea5da90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_phate_denoised.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eca862-75e8-4a86-9d5a-64c473425541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_phate_denoised.save_as_gif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d78b2d-d7b3-4c51-be3d-870ef97b23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_phate_denoised.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed12ca-b196-412b-8aa6-c4e5cd734c2d",
   "metadata": {},
   "source": [
    "### M-PHATE Hyperparameter Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c94bff-3c48-4353-82df-7ad211ba820d",
   "metadata": {},
   "source": [
    "This section explores the effect of key M-PHATE hyperparameters on the temporal embedding structure. We vary one parameter at a time while keeping all others fixed, and visualize the resulting animations side by side.\n",
    "\n",
    "**Parameters explored:**\n",
    "- **Diffusion time `t`**: Controls how far information diffuses across the affinity graph. Higher values lead to smoother, more global embeddings. We test `t ∈ {10, 20, 30, 'auto'}`.\n",
    "- **Interslice KNN `interslice_knn`**: Determines how strongly embeddings are connected across time steps. Larger values enforce stronger temporal smoothness. We test `interslice_knn ∈ {10, 20, 30}`.\n",
    "- **Distance potential `gamma`**: Modifies the information distance used in the diffusion process. `gamma=0` corresponds to the default square-root potential; higher values approximate PHATE’s log potential. We test `gamma ∈ {0.0, 0.05, 0.1}`.\n",
    "\n",
    "Each variant is visualized using `show_animations`, optionally with confusion matrices to aid interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976263c-936a-4fb1-a64d-912df9335ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_animation = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962dd6da-301c-483e-9fb2-59d11894233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [10, 20, 30, 'auto']:\n",
    "    emb = compute_mphate_embeddings(run, verbose=False, t=t)\n",
    "    title = f\"M-PHATE (t={t})\"\n",
    "    phate_animation[f\"t={t}\"] = mphate_to_animation(emb, run, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b65e534-bcfa-4734-9bbc-41829150824f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helper.visualization import show_animations\n",
    "\n",
    "show_animations(\n",
    "    animations=[\n",
    "        phate_animation[\"t=10\"],\n",
    "        phate_animation[\"t=20\"],\n",
    "        phate_animation[\"t=30\"],\n",
    "        phate_animation[\"t=auto\"]\n",
    "    ],\n",
    "    figsize_per_plot=(4, 4),\n",
    "    add_confusion_matrix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c8a2b-87e7-4446-8daa-a7f086c9bf2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phate_animation[\"t=10\"].evaluate()\n",
    "phate_animation[\"t=20\"].evaluate()\n",
    "phate_animation[\"t=30\"].evaluate()\n",
    "phate_animation[\"t=auto\"].evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948eb9be-ca0a-4067-96cb-0e326017c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for knn in [10, 20, 30]:\n",
    "    emb = compute_mphate_embeddings(run, verbose=False, interslice_knn=knn)\n",
    "    title = f\"M-PHATE (interslice_knn={knn})\"\n",
    "    phate_animation[f\"knn={knn}\"] = mphate_to_animation(emb, run, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e52378-58cc-463c-9f1c-cb54966385fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    animations=[\n",
    "        phate_animation[\"knn=10\"],\n",
    "        phate_animation[\"knn=20\"],\n",
    "        phate_animation[\"knn=30\"]\n",
    "    ],\n",
    "    figsize_per_plot=(4, 4),\n",
    "    add_confusion_matrix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a6439-3cb8-4e6d-8c67-5dcd8b78a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_animation[\"knn=10\"].evaluate(figsize=(10, 5))\n",
    "phate_animation[\"knn=20\"].evaluate(figsize=(10, 5))\n",
    "phate_animation[\"knn=30\"].evaluate(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452afdf8-0232-4740-b082-2d0fe6243dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.plots import show_phate_graphs\n",
    "\n",
    "show_phate_graphs(\n",
    "    animations=[\n",
    "        phate_animation[\"knn=10\"],\n",
    "        phate_animation[\"knn=20\"],\n",
    "        phate_animation[\"knn=30\"]\n",
    "    ],\n",
    "    figsize_per_plot=(5, 5),\n",
    "    start_epoch=150,\n",
    "    end_epoch=250,\n",
    "    show_class_coloring=False,\n",
    "    show_epoch_coloring=True,\n",
    "    point_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30a05c-16a0-436a-9bdd-1779184e68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gamma in [0.0, 0.05, 0.1, 0.2]:\n",
    "    emb = compute_mphate_embeddings(run, verbose=False, gamma=gamma)\n",
    "    title = f\"M-PHATE (gamma={gamma})\"\n",
    "    phate_animation[f\"gamma={gamma}\"] = mphate_to_animation(emb, run, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d97a4d-270c-4f81-b536-ffcc949871f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animations(\n",
    "    animations=[\n",
    "        phate_animation[\"gamma=0.0\"],\n",
    "        phate_animation[\"gamma=0.05\"],\n",
    "        phate_animation[\"gamma=0.1\"],\n",
    "        phate_animation[\"gamma=0.2\"]\n",
    "    ],\n",
    "    figsize_per_plot=(4, 4),\n",
    "    add_confusion_matrix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a7d28-37de-424d-bb63-e2b5d3de2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_animation[\"gamma=0.0\"].evaluate()\n",
    "phate_animation[\"gamma=0.05\"].evaluate()\n",
    "phate_animation[\"gamma=0.1\"].evaluate()\n",
    "phate_animation[\"gamma=0.2\"].evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9dc63-5049-4823-a15b-7bd35e00bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.plots import show_phate_graphs\n",
    "\n",
    "show_phate_graphs(\n",
    "    animations=[\n",
    "        phate_animation[\"gamma=0.0\"],\n",
    "        phate_animation[\"gamma=0.05\"],\n",
    "        phate_animation[\"gamma=0.1\"],\n",
    "        phate_animation[\"gamma=0.2\"]\n",
    "    ],\n",
    "    figsize_per_plot=(5, 5),\n",
    "    start_epoch=10,\n",
    "    end_epoch=30,\n",
    "    show_class_coloring=False,\n",
    "    show_epoch_coloring=True,\n",
    "    point_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f6a75e-b7dd-41e4-b7bd-80dfedd3e4de",
   "metadata": {},
   "source": [
    "### Or as single plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90284dd9-be4e-4a24-930c-1d8431cc4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.plots import plot_mphate_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432633e2-d723-48f9-a852-4f2f281af44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mphate_over_time(\n",
    "    mphate_emb,\n",
    "    run,\n",
    "    start_epoch=50,\n",
    "    end_epoch=None,\n",
    "    show_class_coloring=True,\n",
    "    show_epoch_coloring=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa256162-7550-408a-86f5-07befbd677f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mphate_over_time(\n",
    "    mphate_emb,\n",
    "    run,\n",
    "    start_epoch=100,\n",
    "    end_epoch=None,\n",
    "    show_class_coloring=False,\n",
    "    show_epoch_coloring=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98173e5d-f75f-49c2-8938-0ca42de16771",
   "metadata": {},
   "source": [
    "### Class mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c95412b-9997-4abc-9eed-a4fe6d2781d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cmap = plt.cm.tab10\n",
    "\n",
    "# ---- Define your epoch range ----\n",
    "start_epoch = 0\n",
    "end_epoch = 200\n",
    "\n",
    "# ---- Slice data ----\n",
    "selected_emb = mphate_emb[start_epoch:end_epoch]\n",
    "selected_epochs = end_epoch - start_epoch\n",
    "selected_norm = plt.Normalize(vmin=start_epoch, vmax=end_epoch - 1)\n",
    "\n",
    "\n",
    "unique_classes = np.unique(labels)\n",
    "n_classes = len(unique_classes)\n",
    "\n",
    "# --- Compute class centroids over time ---\n",
    "class_centroids = []\n",
    "for idx in range(selected_emb.shape[0]):  # over selected epochs\n",
    "    epoch_emb = selected_emb[idx]\n",
    "    centroids = []\n",
    "    for c in unique_classes:\n",
    "        class_mask = (labels == c)\n",
    "        centroids.append(epoch_emb[class_mask].mean(axis=0))\n",
    "    class_centroids.append(np.stack(centroids))\n",
    "\n",
    "class_centroids = np.stack(class_centroids)  # shape: (epochs, classes, dims)\n",
    "\n",
    "# --- Plot centroids as lines per class ---\n",
    "plt.figure(figsize=(10, 8))\n",
    "for c in range(n_classes):\n",
    "    plt.plot(\n",
    "        class_centroids[:, c, 0],\n",
    "        class_centroids[:, c, 1],\n",
    "        color=class_cmap(c),\n",
    "        label=class_names[c]\n",
    "    )\n",
    "\n",
    "plt.title(f\"Class centroid trajectories (epochs {start_epoch}-{end_epoch})\")\n",
    "plt.xlabel(\"M-PHATE dim 1\")\n",
    "plt.ylabel(\"M-PHATE dim 2\")\n",
    "plt.legend(title=\"Classes\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phate-env",
   "language": "python",
   "name": "phate-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
